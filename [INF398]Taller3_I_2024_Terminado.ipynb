{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5rfZ_hYaQ1Z"
      },
      "source": [
        "<img src=\"https://www.inf.utfsm.cl/images/slides/Departamento-de-Informtica_HORIZONTAL.png\" title=\"Title text\" width=\"80%\" />\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "<h1 align='center'> INF-398 Introducción al Aprendizaje Automático I-2024 </h1>\n",
        "\n",
        "<H3 align='center'> Taller 3 </H3>\n",
        "\n",
        "<H5 align='center'>  </H3>\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integrantes: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Natalia Barraza \n",
        "* Cristian Marín"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KovasDMUMnW"
      },
      "source": [
        "# Temas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUgiKCl3UREw"
      },
      "source": [
        "* SVM\n",
        "* Árboles\n",
        "* KNN\n",
        "* Ensembles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hHigypDURhb"
      },
      "source": [
        "# Reglas & Formalidades\n",
        "\n",
        "* Equipos de 2 integrantes.\n",
        "* Pueden reusar código visto en clases y/o recolectar código/ideas de otros sitios, mencionando al autor y entregando un link a la fuente.\n",
        "* Si resulta necesaria, la intervención de personas ajenas al grupo (e.g. experto) debe ser declarada y justificada.\n",
        "* Tener roles dentro del equipo está bien, pero al final del proceso, cada miembro debe entender y estar en condiciones de exponer todo el trabajo realizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQeZ0_M7Ucf-"
      },
      "source": [
        "# Entregables\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DOvGvOZUZYV"
      },
      "source": [
        "\n",
        "> * **Video:** Se debe preparar un video explicativo de **máx 15 minutos** donde se describe la metodología utilizada, los resultados obtenidos y las conclusiones de la experiencia.\n",
        "\n",
        "> * **Código:** Se debe enviar un jupyter notebook con el código utilizado, de modo que sea posible **reproducir los resultados** presentados. Como alternativa, se puede entregar un link Github con el código fuente, incluyendo instrucciones precisas para ejecutar los experimentos. En cualquier caso (notebook o repo) el código debe estar ordenado y seccionado apropiadamente.\n",
        "\n",
        "> * **Conformidad Ética:** Se debe incluir una breve declaración ética en que se indique que el trabajo que se está enviando es un trabajo original, desarollado por los autores en conformidad con todas reglas antes mencionadas. Se debe también mencionar brevemente cuál fue la contribución de cada miembro del equipo. La declaración puede ser parte del notebook o estar en un archivo dentro del repo.\n",
        "\n",
        "> * **Defensa en vivo:** El día de clases agendado para la discusión del taller, se seleccionarán aleatoriamente algunos equipos que presentarán oralmente su trabajo ante el curso. Los autores serán evaluados considerando la discusión y debate que generen entre sus pares. Los puntos obtenidos (positivos o negativos) se sumarán a la nota final de taller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNyRw2PdUgaA"
      },
      "source": [
        "# Fechas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lmzliloUhux"
      },
      "source": [
        "> * Defensas: 11 de julio, horario de clases.\n",
        "> * Fecha de entrega de vídeo y Jupyter (notebook): 11 de julio 23:59 Hrs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnZJyoJGUmf9"
      },
      "source": [
        "# Instrucciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF1q0Ei3Un6K"
      },
      "source": [
        "EL taller consiste en:\n",
        "\n",
        ">  **Desafío Kaggle (100%)**. Para esta parte, los autores enfrentarán un desafío en la plataforma Kaggle y serán calificados en base a su posición en el tablero de resultados y el puntaje obtenido.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mro0DvciPO8t"
      },
      "source": [
        "# Desafío Kaggle\n",
        "\n",
        "\n",
        "\n",
        "Para esta parte del taller, tendrán que constuir un modelo capaz de predecir el precio de una vivienda, considerando los atributos entregados, como cantidad de piezas, ubicacion, etc.\n",
        "Algunas consideraciones:\n",
        "\n",
        "\n",
        "*   Los unicos modelos que **no** estarán permitidos son las **Redes Neuronales y lo relacionado a Deep Learning.**\n",
        "*   Se debe efectuar comparacion de modelos, ya sea un solo modelo y el efecto de la modificacion de hiperparametros o diferentes modelos.\n",
        "* Deben incluir una Tabla con resultados finales, resultado de la comparacion.\n",
        "* **Deben considerar como alternativa lo visto en T-12 Ensamblados**.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Para acceder a loss detalles del desafío ingrese al siguiente link:\n",
        "\n",
        "https://www.kaggle.com/t/027c57308813443182b66ab44e14f99b\n",
        "\n",
        "**Evaluacion**\n",
        "\n",
        "Según las posiciones en el tablero privado de Kaggle, se asignarán los siguientes puntos adicionales:\n",
        "\n",
        "* 1er Lugar = +5 pts.\n",
        "* 2do y 3er Lugar = +3 pts.\n",
        "* 4to y 5to Lugar = +2 pts.\n",
        "* 6to y 7mo Lugar = +1 pts.\n",
        "* 8vo o más = +0 pts.\n",
        "\n",
        "\n",
        "\n",
        "* No hacer submission a Kaggle = -10 pts.\n",
        "* No superar el puntaje baseline = -5 pts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VVzSTfeQkrBl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import re\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recursos para procesar texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descargar recursos necesarios para NLTK (ejecutar una vez) \n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocesamiento de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('text-train.csv')\n",
        "df_test = pd.read_csv('text-test.csv')\n",
        "\n",
        "# Inicializar el stemmer y la lista de stopwords para italiano\n",
        "stemmer = SnowballStemmer('italian')         #reduce las palabras\n",
        "stop_words = set(stopwords.words('italian')) #elimina conectores en italianno\n",
        "\n",
        "def preprocess_text_italian(text):\n",
        "    if isinstance(text, str):\n",
        "        text = re.sub(r'[^a-zA-Z\\sàèéìíîòóùú\\s]', '', text, re.I|re.A)                  #eliminar todo lo que no sea letras\n",
        "        text = text.lower().strip()                                                     #dejamos todo en minúscula y elimina espacios en blanco al inicio y al final\n",
        "        tokens = nltk.word_tokenize(text, language='italian')                           #Separa el string y lo convierte en un string por cada palabra \n",
        "        tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]   #reduce la palabra solo si no es una palabra 'vacía'\n",
        "        preprocessed_text = ' '.join(tokens)                                            #Se devuelve todo en un solo string\n",
        "        return preprocessed_text\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Aplicar preprocesamiento a las columnas 'title' y 'description' de df_train y df_test\n",
        "df_train['title_clean'] = df_train['title'].apply(preprocess_text_italian)\n",
        "df_train['description_clean'] = df_train['description'].apply(preprocess_text_italian)\n",
        "df_test['title_clean'] = df_test['title'].apply(preprocess_text_italian)\n",
        "df_test['description_clean'] = df_test['description'].apply(preprocess_text_italian)\n",
        "\n",
        "#Se junta el título y la descripción preprocesada\n",
        "X_train = df_train['title_clean'] + ' ' + df_train['description_clean']\n",
        "y_train = df_train['class']\n",
        "X_test = df_test['title_clean'] + ' ' + df_test['description_clean']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrenamiento y comparación de los modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Listas de modelos y parámetros a probar\n",
        "models = [\n",
        "    ('SVM', SVC(kernel='linear', C=1, random_state=42), 'linear'),\n",
        "    ('SVM', SVC(kernel='rbf', C=1, random_state=42), 'rbf'),\n",
        "    ('SVM', SVC(kernel='poly', C=1, random_state=42), 'poly'),\n",
        "    ('KNN', KNeighborsClassifier(n_neighbors=3), 3),\n",
        "    ('KNN', KNeighborsClassifier(n_neighbors=5), 5),\n",
        "    ('KNN', KNeighborsClassifier(n_neighbors=7), 7),\n",
        "    ('RandomForest', RandomForestClassifier(n_estimators=50, random_state=42), 50),\n",
        "    ('RandomForest', RandomForestClassifier(n_estimators=100, random_state=42), 100),\n",
        "    ('RandomForest', RandomForestClassifier(n_estimators=200, random_state=42), 200)\n",
        "]\n",
        "\n",
        "# Tabla comparativa de resultados\n",
        "results = []\n",
        "\n",
        "for model_name, model, param in models:\n",
        "    pipeline = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        (model_name.lower(), model)\n",
        "    ])\n",
        "    \n",
        "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "    \n",
        "    f1_scores = cross_val_score(pipeline, X_train_split, y_train_split, cv=3, scoring='f1_macro')\n",
        "    mean_f1 = f1_scores.mean()\n",
        "    \n",
        "    results.append((model_name, param, mean_f1))\n",
        "    \n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    \n",
        "    results_df = pd.DataFrame({'id': df_test.index, 'class': y_pred})\n",
        "    results_df.to_csv(f'resultados_clasificacion_{model_name.lower()}_{param}.csv', index=False)\n",
        "    \n",
        "    joblib.dump(pipeline, f'{model_name.lower()}_{param}_model.pkl')\n",
        "\n",
        "# Crear DataFrame con resultados comparativos\n",
        "results_df = pd.DataFrame(results, columns=['Model', 'Parameter', 'F1 Score'])\n",
        "results_df.to_csv('comparativa_resultados.csv', index=False)\n",
        "\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Parameter</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVM</td>\n",
              "      <td>linear</td>\n",
              "      <td>0.909054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.903913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVM</td>\n",
              "      <td>poly</td>\n",
              "      <td>0.801330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KNN</td>\n",
              "      <td>3</td>\n",
              "      <td>0.833350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KNN</td>\n",
              "      <td>5</td>\n",
              "      <td>0.828724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNN</td>\n",
              "      <td>7</td>\n",
              "      <td>0.821660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>50</td>\n",
              "      <td>0.903600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>100</td>\n",
              "      <td>0.906338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>200</td>\n",
              "      <td>0.905288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Model Parameter  F1 Score\n",
              "0           SVM    linear  0.909054\n",
              "1           SVM       rbf  0.903913\n",
              "2           SVM      poly  0.801330\n",
              "3           KNN         3  0.833350\n",
              "4           KNN         5  0.828724\n",
              "5           KNN         7  0.821660\n",
              "6  RandomForest        50  0.903600\n",
              "7  RandomForest       100  0.906338\n",
              "8  RandomForest       200  0.905288"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = pd.read_csv('MODELOS FINALES/comparativa_resultados.csv')  \n",
        "results_df  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uso del ensamble con 3 distintos modelos "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dividir X_train e y_train en conjuntos de entrenamiento y validación\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definir los modelos que quieres incluir en el VotingClassifier\n",
        "svm_linear = Pipeline([\n",
        "    ('tfidf_svm', TfidfVectorizer()),\n",
        "    ('svm', SVC(kernel='linear', C=1, random_state=42))\n",
        "])\n",
        "\n",
        "knn_3 = Pipeline([\n",
        "    ('tfidf_knn', TfidfVectorizer()),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=3))\n",
        "])\n",
        "\n",
        "random_forest_100 = Pipeline([\n",
        "    ('tfidf_rf', TfidfVectorizer()),\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Crear el VotingClassifier\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('svm_linear', svm_linear),\n",
        "    ('knn_3', knn_3),\n",
        "    ('random_forest_100', random_forest_100)\n",
        "], voting='hard')\n",
        "\n",
        "# Entrenar el VotingClassifier con el conjunto de entrenamiento\n",
        "voting_clf.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Predecir con el conjunto de validación\n",
        "y_val_pred = voting_clf.predict(X_val)\n",
        "\n",
        "# Calcular la métrica F1 en el conjunto de validación\n",
        "f1_val = f1_score(y_val, y_val_pred, average='weighted')\n",
        "print(f\"Métrica F1 en el conjunto de validación: {f1_val}\")\n",
        "\n",
        "# Entrenar el VotingClassifier con todos los datos de entrenamiento\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predecir con el VotingClassifier entrenado en el conjunto de prueba final\n",
        "y_pred_voting = voting_clf.predict(X_test)\n",
        "\n",
        "# Guardar los resultados de la votación mayoritaria\n",
        "results_voting_df = pd.DataFrame({'id': df_test.index, 'class': y_pred_voting})\n",
        "results_voting_df.to_csv('resultados_clasificacion_voting.csv', index=False)\n",
        "\n",
        "# Guardar el modelo de votación mayoritaria\n",
        "joblib.dump(voting_clf, 'voting_model.pkl')\n",
        "\n",
        "print(\"Resultados de la clasificación por mayoría de votos guardados en 'resultados_clasificacion_voting.csv'\")\n",
        "print(\"Modelo de votación por mayoría guardado en 'voting_model.pkl'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El resultado de la métrica f1 en el voting fue de 0.9413215403982274 en el conjunto de validación (es lo que entrega el print aprox. si se llegase a ejecutar el código)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
